{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from string import Template\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batting_data(years):\n",
    "    chromedriver = \"/Applications/chromedriver\"\n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    url_base = Template('https://www.baseball-reference.com/leagues/MLB/$year-standard-batting.shtml')\n",
    "    df_list = []\n",
    "    for year in years:\n",
    "        url = url_base.substitute(year=year)\n",
    "        driver.get(url)\n",
    "        tables = pd.read_html(driver.page_source)\n",
    "        df = tables[len(tables) - 1]\n",
    "        df_list.append(df)\n",
    "        time.sleep(1);\n",
    "    return df_list\n",
    "\n",
    "def get_value_data():\n",
    "    chromedriver = \"/Applications/chromedriver\"\n",
    "    os.environ[\"webdriver.chrome.driver\"] = chromedriver\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    driver.get('https://www.baseball-reference.com/leagues/MLB/2018-value-batting.shtml')\n",
    "    tables = pd.read_html(driver.page_source)\n",
    "    df_value = tables[len(tables) - 1]\n",
    "    return df_value\n",
    "\n",
    "def pickle_3yr_data():\n",
    "    years = [2015, 2016, 2017]\n",
    "    df_list = get_batting_data(years)\n",
    "    df_value = get_value_data()\n",
    "    pickle_object = (df_list, df_value)\n",
    "    with open(\"batting_value_pickle.pkl\", \"wb\") as f:\n",
    "        pickle.dump(pickle_object, f)\n",
    "    \n",
    "def clean_salary_data():\n",
    "    with open(\"batting_value_pickle.pkl\", \"rb\") as f:\n",
    "        pickle_object = pickle.load(f)\n",
    "    df_value = pickle_object[1]\n",
    "    df_value.columns = [x.strip() for x in df_value.columns]\n",
    "    drop_columns = ['Rk', 'Age', 'Tm', 'G', 'PA', 'Rbat', 'Rbaser', 'Rdp', 'Rfield', 'Rpos', 'RAA', 'WAA', 'Rrep',\n",
    "                'RAR', 'WAR', 'waaWL%', '162WL%', 'oWAR','dWAR', 'oRAR','Acquired']\n",
    "    df_salary = df_value.drop(drop_columns, axis=1)\n",
    "    df_salary.columns = ['Name', 'salary', 'position']\n",
    "    df_salary.dropna(axis=0, how = 'any', inplace=True)\n",
    "    df_salary = df_salary[df_salary['Name'] != 'Name']\n",
    "    df_salary['salary'] = df_salary['salary'].str.replace(',', '')\n",
    "    df_salary['salary'] = df_salary['salary'].str.replace('$', '')\n",
    "    df_salary['salary'] = df_salary['salary'].astype(int)\n",
    "    df_salary = df_salary[~df_salary['position'].str.contains('1')]\n",
    "    df_salary = df_salary[df_salary['salary'] > 1000000]\n",
    "    df_salary = df_salary.drop('position', axis=1)\n",
    "    return df_salary\n",
    "\n",
    "def clean_batting_data(df):\n",
    "    df.columns = [x.strip() for x in df.columns]\n",
    "    df.dropna(axis=0, how = 'any', inplace=True)\n",
    "    df = df[df['Name'] != 'Name']\n",
    "    df = df.drop_duplicates(subset = 'Name', keep = 'first')\n",
    "    columns = ['Name', 'Age', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B',\n",
    "       'HR', 'RBI', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+',\n",
    "       'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB']\n",
    "    df = df[columns]\n",
    "    float_columns = ['Age', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B',\n",
    "       'HR', 'RBI', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'OPS+',\n",
    "       'TB', 'GDP', 'HBP', 'SH', 'SF', 'IBB']\n",
    "    df[float_columns] = df[float_columns].astype('float')\n",
    "    return df\n",
    "\n",
    "def combine_data():\n",
    "    with open(\"batting_value_pickle.pkl\", \"rb\") as f:\n",
    "        pickle_object = pickle.load(f)\n",
    "    df_list = pickle_object[0]\n",
    "    df_batting_2015 = df_list[0]\n",
    "    df_batting_2015 = clean_batting_data(df_batting_2015)\n",
    "    df_batting_2016 = df_list[1]\n",
    "    df_batting_2016 = clean_batting_data(df_batting_2016)\n",
    "    df_batting_2017 = df_list[2]\n",
    "    df_batting_2017 = clean_batting_data(df_batting_2017)\n",
    "    df_salary = clean_salary_data()\n",
    "    df_combined = pd.merge(df_salary, df_batting_2015, how = 'left', on='Name')\n",
    "    df_combined = df_combined.merge(df_batting_2016, on='Name', how='left', suffixes=(\"_2015\", \"_2016\"))\n",
    "    df_combined = df_combined.merge(df_batting_2017, on='Name', how='left')\n",
    "    df_combined.dropna(axis=0, how='any', inplace=True)\n",
    "    return df_combined\n",
    "\n",
    "def calculate_average_features(df_combined):\n",
    "    df_avg_features = df_combined.loc[:, ['Name', 'salary']]\n",
    "    df_avg_features['avg_age'] = (df_combined.loc[:, 'Age_2016']).astype('int')\n",
    "    df_avg_features['avg_games'] = ((df_combined['G_2015'] + df_combined['G_2016'] + df_combined['G']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_PA'] = ((df_combined['PA_2015'] + df_combined['PA_2016'] + df_combined['PA']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_AB'] = ((df_combined['AB_2015'] + df_combined['AB_2016'] + df_combined['AB']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_R'] = ((df_combined['R_2015'] + df_combined['R_2016'] + df_combined['R']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_H'] = ((df_combined['H_2015'] + df_combined['H_2016'] + df_combined['H']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_2B'] = ((df_combined['2B_2015'] + df_combined['2B_2016'] + df_combined['2B']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_3B'] = ((df_combined['3B_2015'] + df_combined['3B_2016'] + df_combined['3B']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_HR'] = ((df_combined['HR_2015'] + df_combined['HR_2016'] + df_combined['HR']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_RBI'] = ((df_combined['RBI_2015'] + df_combined['RBI_2016'] + df_combined['RBI']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_BB'] = ((df_combined['BB_2015'] + df_combined['BB_2016'] + df_combined['BB']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_SO'] = ((df_combined['SO_2015'] + df_combined['SO_2016'] + df_combined['SO']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_BA'] = ((df_combined['BA_2015'] + df_combined['BA_2016'] + df_combined['BA']) / 3.0)\n",
    "    df_avg_features['avg_OBP'] = ((df_combined['OBP_2015'] + df_combined['OBP_2016'] + df_combined['OBP']) / 3.0)\n",
    "    df_avg_features['avg_SLG'] = ((df_combined['SLG_2015'] + df_combined['SLG_2016'] + df_combined['SLG']) / 3.0)\n",
    "    df_avg_features['avg_OPS'] = ((df_combined['OPS_2015'] + df_combined['OPS_2016'] + df_combined['OPS']) / 3.0)\n",
    "    df_avg_features['avg_OPS+'] = ((df_combined['OPS+_2015'] + df_combined['OPS+_2016'] + df_combined['OPS+']) / 3.0)\n",
    "    df_avg_features['avg_TB'] = ((df_combined['TB_2015'] + df_combined['TB_2016'] + df_combined['TB']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_GDP'] = ((df_combined['GDP_2015'] + df_combined['GDP_2016'] + df_combined['GDP']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_HBP'] = ((df_combined['HBP_2015'] + df_combined['HBP_2016'] + df_combined['HBP']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_SH'] = ((df_combined['SH_2015'] + df_combined['SH_2016'] + df_combined['SH']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_SF'] = ((df_combined['SF_2015'] + df_combined['SF_2016'] + df_combined['SF']) / 3.0).astype('int')\n",
    "    df_avg_features['avg_IBB'] = ((df_combined['IBB_2015'] + df_combined['IBB_2016'] + df_combined['IBB']) / 3.0).astype('int')\n",
    "    return df_avg_features\n",
    "\n",
    "def simple_features(df_avg_features):\n",
    "    simple_columns = ['salary', 'avg_R', 'avg_H', 'avg_RBI', 'avg_BB', 'avg_SO',\n",
    "        'avg_GDP', 'avg_HBP', 'avg_SH', 'avg_SF', 'avg_IBB']\n",
    "    df_simple = df_avg_features[simple_columns]\n",
    "    return df_simple\n",
    "\n",
    "def linear_regression_model(df):\n",
    "    X = df[[x for x in df.columns if x != 'salary']]\n",
    "    y = df['salary']\n",
    "    X_train, X_test, y_train, y_test = tts(X, y, test_size=0.3, random_state=42)\n",
    "    y_train = np.log(y_train)\n",
    "    y_test = np.log(y_test)\n",
    "    ssX = StandardScaler()\n",
    "    ssX.fit(X_train)\n",
    "    X_train = ssX.transform(X_train)\n",
    "    X_test = ssX.transform(X_test)\n",
    "    model= LinearRegression()\n",
    "    model = model.fit(X_train, y_train)\n",
    "    return model, X_train, X_test, y_train, y_test\n",
    "\n",
    "def mse(model, X, y):\n",
    "    y_predict = model.predict(X)\n",
    "    mse = mean_squared_error(y, y_predict)\n",
    "    return mse\n",
    "\n",
    "def mae(model, X, y):\n",
    "    y_exp = np.exp(y)\n",
    "    y_predict = model.predict(X)\n",
    "    y_predict_exp = np.exp(y_predict)\n",
    "    mae = mean_absolute_error(y_exp, y_predict_exp)\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_3yr_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean squared error =  0.38674348867827474 test mean squared error =  0.37127053929629716 mean_absolute_error =  4145517.9500637283\n"
     ]
    }
   ],
   "source": [
    "df_combined = combine_data()\n",
    "df_average_features = calculate_average_features(df_combined)\n",
    "df_simple = simple_features(df_average_features)\n",
    "model, X_train, X_test, y_train, y_test = linear_regression_model(df_simple)\n",
    "mse_test = mse(model, X_test, y_test)\n",
    "mse_train = mse(model, X_train, y_train)\n",
    "mae = mae(model, X_test, y_test)\n",
    "print(\"train mean squared error = \", mse_train, \"test mean squared error = \", mse_test, \"mean_absolute_error = \", mae )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
